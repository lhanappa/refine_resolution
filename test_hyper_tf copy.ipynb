{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit648325705e4b41c8bbabe44d0e358718",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cooler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "\n",
    "from iced import normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from ftp://cooler.csail.mit.edu/coolers/hg19/\n",
    "name = 'Dixon2012-H1hESC-HindIII-allreps-filtered.100kb.cool'\n",
    "#name = 'Rao2014-K562-MboI-allreps-filtered.500kb.cool'\n",
    "c = cooler.Cooler(name)\n",
    "resolution = c.binsize\n",
    "mat= c.matrix(balance=True).fetch('chr2')\n",
    "print(mat.shape)\n",
    "idxy = ~np.all(np.isnan(mat),axis=0)\n",
    "M = mat[idxy,:]\n",
    "Mh = M[:,idxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.log2(Mh), cmap='YlOrRd')\n",
    "hic_hr = []\n",
    "for i in range(len(Mh)-511):\n",
    "    hic_hr.append(Mh[i:i+512, i:i+512])\n",
    "hic_hr = np.array(hic_hr)\n",
    "hic_hr_ds = tf.data.Dataset.from_tensor_slices(hic_hr)\n",
    "print(hic_hr.shape)\n",
    "print(hic_hr_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(np.log2(hic_hr[i*100,:,:]), cmap='YlOrRd')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = int(Mh.shape[0]/4),int(Mh.shape[1]/4)\n",
    "img_l = np.zeros(shape=(IMG_HEIGHT, IMG_WIDTH))\n",
    "for i in list(range(0, len(Mh))):\n",
    "    x = int(np.floor(i/(len(Mh)/IMG_HEIGHT)))\n",
    "    for j in list(range(0,len(Mh))):\n",
    "        y = int(np.floor(j/(len(Mh)/IMG_WIDTH)))\n",
    "        img_l[x, y] = img_l[x, y] + Mh[i,j]\n",
    "'''idxy = ~np.all(np.isnan(mat),axis=0)\n",
    "Ml = matl[idxy,:]\n",
    "Ml = Ml[:,idxy]'''\n",
    "Ml = img_l\n",
    "plt.matshow(np.log2(Ml), cmap='YlOrRd')\n",
    "print(Ml.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "Ml = img_l\n",
    "D = np.sqrt(Ml.sum(axis=0))**(-1)\n",
    "Ml = normalization.ICE_normalization(Ml)\n",
    "#Ml = normalization.SCN_normalization(Ml)\n",
    "print(Ml)\n",
    "plt.matshow(np.log2(Ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hic_lr = []\n",
    "IMG_HEIGHT, IMG_WIDTH = int(512/4),int(512/4)\n",
    "print(IMG_HEIGHT, IMG_WIDTH)\n",
    "for i in range(len(Ml)-IMG_HEIGHT+1):\n",
    "    hic_lr.append(Ml[i:i+IMG_HEIGHT, i:i+IMG_WIDTH])\n",
    "hic_lr = np.array(hic_lr)\n",
    "hic_lr_ds = tf.data.Dataset.from_tensor_slices(hic_lr)\n",
    "print(hic_lr.shape)\n",
    "print(hic_lr_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(np.log2(hic_lr[i*25,:,:]), cmap='YlOrRd')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hic_lr = hic_lr[..., np.newaxis]\n",
    "hic_hr = hic_hr[..., np.newaxis]\n",
    "print(hic_lr.shape)\n",
    "print(hic_hr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDecomposeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, name='BiL'):\n",
    "        super(BinaryDecomposeLayer, self).__init__(name=name)\n",
    "        self.num_outputs = filters\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer(mean=0, stddev=3.0)\n",
    "        self.w = tf.Variable( \n",
    "            initial_value = w_init(shape=(input_shape[1], self.num_outputs), dtype=tf.float32),\n",
    "            trainable=True) \n",
    "        self.w.assign(tf.nn.relu(self.w))\n",
    "        \n",
    "    def call(self, input): \n",
    "        self.w.assign(tf.clip_by_value(self.w, -5.0, 5.0))\n",
    "        self.w.assign(tf.math.tanh(self.w))\n",
    "        H = tf.tensordot(input, self.w, [[1], [0]])\n",
    "        H = tf.sigmoid(H)\n",
    "        '''WT = tf.transpose(self.w, perm=(0,3,2,1))\n",
    "        Up = tf.tensordot(WT, input, [[3], [1]])\n",
    "        Up = tf.squeeze(tf.transpose(Up, perm=[3,1,0,4,5,2]), axis=[-1,-2])\n",
    "        WTW = tf.squeeze(tf.tensordot(WT, self.w, [[3], [1]]), axis=[2,3])\n",
    "        Down = tf.squeeze(tf.tensordot(WTW, WT, [[3], [1]]), axis=[2,3])\n",
    "        #Down = tf.transpose(Down, perm=[0,1,3,2])\n",
    "        H = tf.math.multiply_no_nan(WT, tf.math.divide_no_nan(Up, Down))\n",
    "        H = tf.nn.relu(H)\n",
    "        H = tf.transpose(H, perm=[0,3,2,1])'''\n",
    "        return H\n",
    "\n",
    "class Rank1Reconstruct(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, name='RR'):\n",
    "        super(Rank1Reconstruct, self).__init__(name=name)\n",
    "        self.num_outputs = filters\n",
    "        w_init = tf.ones_initializer()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(1,1,1,filters), dtype='float32'))\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "        \n",
    "    def call(self, input):\n",
    "        v = tf.math.add(input, tf.constant(1e-6))\n",
    "        vt = tf.transpose(v, perm=[0,2,1,3])\n",
    "        rank1m = tf.multiply(tf.multiply(v, vt), 0.01*self.w)\n",
    "        return rank1m\n",
    "\n",
    "class DiagonalWeight(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, name='DW'):\n",
    "        super(DiagonalWeight, self).__init__(name=name)\n",
    "        #w_init = tf.random_normal_initializer()\n",
    "        w_init = tf.ones_initializer()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(1, input_dim), dtype='float32'), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.w.assign(tf.math.maximum(0.0, self.w))\n",
    "        self.w.assign(tf.math.minimum(1.0, self.w))\n",
    "        opw = tf.linalg.LinearOperatorToeplitz(self.w, self.w)\n",
    "\n",
    "        return tf.multiply(inputs, \n",
    "            tf.expand_dims(opw.to_dense(),-1))\n",
    "\n",
    "class Normal(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, name='DW'):\n",
    "        super(Normal, self).__init__(name=name)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        rowsr = tf.math.sqrt(tf.math.reduce_sum(inputs, axis=2, keepdims=True))\n",
    "        colsr = tf.math.sqrt(tf.math.reduce_sum(inputs, axis=1, keepdims=True))\n",
    "        sumele = tf.math.multiply(rowsr, colsr)\n",
    "        return tf.math.divide_no_nan(inputs, sumele)\n",
    "\n",
    "'''# cross entropy -ylog(p)         \n",
    "def basic_loss_function(y_true, y_pred):\n",
    "    p = tf.math.divide_no_nan(tf.math.abs(tf.subtract(y_true, y_pred)), y_true)\n",
    "    phat = tf.math.subtract(tf.ones_like(y_true), p)+tf.constant(1e-4)\n",
    "    log = tf.math.log(phat)\n",
    "    E = tf.math.scalar_mul(-1, tf.math.multiply(y_pred, log))\n",
    "    return tf.math.reduce_mean(E, axis=[1,2,3])'''\n",
    "\n",
    "def basic_loss_function(y_true, y_pred):\n",
    "    return tf.add(\n",
    "        tf.math.reduce_std(tf.math.divide_no_nan(tf.subtract(y_true, y_pred), y_true), axis=[1,2,3]), \n",
    "        tf.math.reduce_mean(tf.math.divide_no_nan(tf.abs(tf.subtract(y_true, y_pred)),y_true), axis=[1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "In = Input(shape=(128, 128, 1), name='In')\n",
    "\n",
    "Dec1 = BinaryDecomposeLayer(16, name='Dec1')(In) \n",
    "Drop1 = tf.keras.layers.Dropout(0.5)(Dec1)\n",
    "Rec1 = Rank1Reconstruct(16, name='Rec1')(Dec1)\n",
    "Sum1 = tf.keras.layers.Conv2D(1, [1,1], use_bias=False, kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1.0), kernel_constraint=tf.keras.constraints.NonNeg(), name='Sum1')(Rec1)\n",
    "\n",
    "Residual2 = tf.keras.layers.Subtract(name='Sub2')([In, Sum1])\n",
    "ReLU2 = tf.keras.layers.ReLU(name='relu2')(Residual2)\n",
    "\n",
    "Dec2 = BinaryDecomposeLayer(32, name='Dec2')(ReLU2) \n",
    "Drop2 = tf.keras.layers.Dropout(0.5)(Dec2)\n",
    "Rec2 = Rank1Reconstruct(32, name='Rec2')(Drop2)\n",
    "Sum2= tf.keras.layers.Conv2D(1, [1,1], use_bias=False, kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=None), kernel_constraint=tf.keras.constraints.NonNeg(), name='Sum2')(Rec2)\n",
    "\n",
    "Residual3 = tf.keras.layers.Subtract(name='Sub3')([ReLU2, Sum2])\n",
    "ReLU3 = tf.keras.layers.ReLU(name='relu3')(Residual3)\n",
    "\n",
    "Dec3 = BinaryDecomposeLayer(64,name='Dec3')(ReLU3) \n",
    "Drop3 = tf.keras.layers.Dropout(0.5)(Dec3)\n",
    "Rec3 = Rank1Reconstruct(64, name='Rec3')(Drop3)\n",
    "Sum3= tf.keras.layers.Conv2D(1, [1,1], use_bias=False, kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=None), kernel_constraint=tf.keras.constraints.NonNeg(), name='Sum3')(Rec3)\n",
    "\n",
    "comb = tf.keras.layers.Add(name='Combine')([Sum1, Sum2, Sum3])\n",
    "dw = DiagonalWeight(128, name='DW')(comb)\n",
    "out = Normal(128, name='Out')(dw)\n",
    "\n",
    "model = Model(inputs=[In],outputs=[out])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "plot_model(model, to_file='demo.png',show_shapes=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                histogram_freq=1,\n",
    "                                             write_images=True, \n",
    "                                             update_freq='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = hic_lr[::30, :,:]\n",
    "print(train_data.shape)\n",
    "test_data = hic_lr[1::2, :,:]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, data):\n",
    "        super(MyCustomCallback, self).__init__()\n",
    "        self.data = data\n",
    "        #print(data.shape)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 8 == 0:\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Dec1').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            fig, axs = plt.subplots(2, 3, constrained_layout=True, figsize=(15,15))\n",
    "            axs[0,0].set_title('Dec1-H')\n",
    "            axs[0,0].imshow(np.squeeze(intermediate_output))\n",
    "            m = np.squeeze(self.model.get_layer('Dec1').get_weights())\n",
    "            axs[1,0].set_title('Dec1-Weights')\n",
    "            axs[1,0].imshow(m)\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Dec2').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[0,1].set_title('Dec2-H')\n",
    "            axs[0,1].imshow(np.squeeze(intermediate_output))\n",
    "            m = np.squeeze(self.model.get_layer('Dec2').get_weights())\n",
    "            axs[1,1].set_title('Dec2-Weights')\n",
    "            axs[1,1].imshow(m)\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Dec3').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[0,2].set_title('Dec3-H')\n",
    "            axs[0,2].imshow(np.squeeze(intermediate_output))\n",
    "            m = np.squeeze(self.model.get_layer('Dec3').get_weights())\n",
    "            axs[1,2].set_title('Dec3-Weights')\n",
    "            axs[1,2].imshow(m)\n",
    "            plt.savefig('./lvl1/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig, axs = plt.subplots(2, 3, constrained_layout=True, figsize=(30,15))\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Sum1').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[0,0].set_title('sum1')\n",
    "            axs[0,0].imshow(np.squeeze(intermediate_output))\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Sum2').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[0,1].set_title('Sum2')\n",
    "            axs[0,1].imshow(np.squeeze(intermediate_output))\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Sum3').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[0,2].set_title('Sum3')\n",
    "            axs[0,2].imshow(np.squeeze(intermediate_output))\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('relu2').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[1,0].set_title('ReLU2')\n",
    "            axs[1,0].imshow(np.squeeze(intermediate_output))\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('relu3').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[1,1].set_title('ReLU3')\n",
    "            axs[1,1].imshow(np.squeeze(intermediate_output))\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Out').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            axs[1,2].set_title('Out')\n",
    "            axs[1,2].imshow(np.squeeze(intermediate_output))\n",
    "            plt.savefig('./lvl2/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "            plt.close(fig)\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('DW').output)\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            #print(intermediate_output.shape)\n",
    "            fig = plt.figure(figsize=(27, 9))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(intermediate_output[0, :, :, 0], cmap='YlOrRd')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            w = self.model.get_layer('DW').get_weights()[0]\n",
    "            plt.imshow(np.squeeze(tf.linalg.LinearOperatorToeplitz(w, w).to_dense()), cmap='YlOrRd')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(np.log2(np.squeeze(intermediate_output[0, :, :, 0])))\n",
    "            plt.colorbar()\n",
    "            plt.savefig('./lvl3/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "            plt.close(fig)\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Rec1').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            #print(intermediate_output.shape)\n",
    "            fig = plt.figure(figsize=(30, 30))\n",
    "            for i in range(0,intermediate_output.shape[3]):\n",
    "                plt.subplot(16, 16, int(i+1))\n",
    "                plt.imshow(np.log2(np.squeeze(intermediate_output[0, :, :, i])), cmap='YlOrRd')\n",
    "                plt.axis('off')\n",
    "            \n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Rec2').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            #print(intermediate_output.shape)\n",
    "            for i in range(0, intermediate_output.shape[3]):\n",
    "                plt.subplot(16, 16, int(17+i))\n",
    "                plt.imshow(np.log2(np.squeeze(intermediate_output[0, :, :, i])), cmap='YlOrRd')\n",
    "                plt.axis('off')\n",
    "\n",
    "            intermediate_layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer('Rec3').output )\n",
    "            intermediate_output = intermediate_layer_model.predict(self.data)\n",
    "            #print(intermediate_output.shape)\n",
    "            for i in range(0, intermediate_output.shape[3]):\n",
    "                plt.subplot(16, 16, int(17+32+i))\n",
    "                plt.imshow(np.squeeze(intermediate_output[0, :, :, i]), cmap='YlOrRd')\n",
    "                plt.axis('off')\n",
    "            plt.savefig('./lvl4/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[0,:,:,:].shape)\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.squeeze(train_data[0,:,:,:]))\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.log2(np.squeeze(train_data[0,:,:,:])))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "demo1 = np.ones(shape=[1,128,128,1])\n",
    "demo1[0,:,:,:] = train_data[0,:,:,:]\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.squeeze(demo1[0,:,:,:]))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.log2(np.squeeze(demo1[0,:,:,:])))\n",
    "\n",
    "_ = model.fit(train_data, train_data,\n",
    "          epochs=800,\n",
    "          batch_size=2,\n",
    "          callbacks=[MyCustomCallback(demo1)])\n",
    "score = model.evaluate(test_data, test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo1[0,:,:,:] = test_data[0,:,:,:]\n",
    "pre = model.predict(demo1)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.squeeze(pre[0,:,:,:]))\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.log2(np.squeeze(pre[0,:,:,:])))\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.log2(np.squeeze(demo1)))\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.log2(np.squeeze(np.abs(pre-demo1))))\n",
    "plt.colorbar()\n",
    "print(np.abs(pre-demo1).sum())\n",
    "print(pre.sum())\n",
    "print(demo1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def train_step(model, dataset, optimizer):\n",
    "    loss_fn = tf.keras.losses.KLDivergence()\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(dataset)\n",
    "        loss = loss_fn(prediction, dataset)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def train(dataset, EPOCHS):\n",
    "    for epoch in range(EPOCHS):\n",
    "        avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)\n",
    "        optimizer=tf.keras.optimizers.Adam()\n",
    "        start = time.time()\n",
    "        for i, image_batch in enumerate(dataset):\n",
    "            loss = train_step(model, image_batch, optimizer)\n",
    "            avg_loss.update_state(loss)    \n",
    "            tf.summary.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
    "            avg_loss.reset_states()\n",
    "            if i>10:\n",
    "                break\n",
    "        print('Time for epoch {} is  {} sec'.format(epoch + 1, time.time() - start))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EPOCHS = 20\n",
    "num_examples = 16\n",
    "BUFFER_SIZE = 600\n",
    "BATCH_SIZE = 32\n",
    "import time\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train(train_dataset, EPOCHS)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import glob\n",
    "anim_file = 'mf_hy_3.gif'\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('./lvl3/image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "if IPython.version_info > (6,2,0,''):\n",
    "    IPython.display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}